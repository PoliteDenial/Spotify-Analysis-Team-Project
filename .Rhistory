library(reticulate) #python cells and interaction with R requires miniConda
#install.packages("remotes") #
#remotes::install_github("mvkorpel/pickURL")
reticulate::repl_python()
import pyautogui as pygui
import win32clipboard
import sys
print(pygui.size()) #gets size of primarary monitor
f = open("AutoData.txt", "a")
def pasteToFile():
win32clipboard.OpenClipboard()
data = win32clipboard.GetClipboardData()
f.write(data)
print(data)
win32clipboard.CloseClipboard()
def copyTable():
pygui.moveTo(161, 787)
pygui.click(button = 'right')
pygui.moveTo(161, 767)
pygui.click(button = 'left')
pygui.moveTo(1282, 380)
pygui.click(button = 'right')
pygui.moveTo(1282, 528)
pygui.moveTo(1382, 528, duration = 0.5)
pygui.moveTo(1582, 528, )
pygui.click(button = 'left')
def selectPrevWeek():
pygui.moveTo(275,745)
pygui.click(button = 'left')
pygui.scroll(-110)
copyTable()
pasteToFile()
#selectPrevWeek()
f = open("AutoData.txt", "a")
f.write("Test")
def pasteToFile():
win32clipboard.OpenClipboard()
data = win32clipboard.GetClipboardData()
f.write(data)
print(data)
win32clipboard.CloseClipboard()
def copyTable():
pygui.moveTo(161, 787)
pygui.click(button = 'right')
pygui.moveTo(161, 767)
pygui.click(button = 'left')
pygui.moveTo(1282, 380)
pygui.click(button = 'right')
pygui.moveTo(1282, 528)
pygui.moveTo(1382, 528, duration = 0.5)
pygui.moveTo(1582, 528, )
pygui.click(button = 'left')
def selectPrevWeek():
pygui.moveTo(275,745)
pygui.click(button = 'left')
pygui.scroll(-110)
copyTable()
#pasteToFile()
#selectPrevWeek()
f = open("AutoData.txt", "a")
f.write("Test")
def pasteToFile():
win32clipboard.OpenClipboard()
data = win32clipboard.GetClipboardData()
f.write(data)
print(data)
win32clipboard.CloseClipboard()
def copyTable():
pygui.moveTo(161, 787)
pygui.click(button = 'right')
pygui.moveTo(161, 767)
pygui.click(button = 'left')
pygui.moveTo(1282, 380)
pygui.click(button = 'right')
pygui.moveTo(1282, 528)
pygui.moveTo(1382, 528, duration = 0.5)
pygui.moveTo(1582, 528, )
pygui.click(button = 'left')
def selectPrevWeek():
pygui.moveTo(275,745)
pygui.click(button = 'left')
pygui.scroll(-110)
copyTable()
#pasteToFile()
#selectPrevWeek()
f = open("AutoData.txt", "a")
f.write("Test")
def pasteToFile():
win32clipboard.OpenClipboard()
data = win32clipboard.GetClipboardData()
f.write(data)
print(data)
win32clipboard.CloseClipboard()
def copyTable():
pygui.moveTo(161, 787)
pygui.click(button = 'right')
pygui.moveTo(161, 767)
pygui.click(button = 'left')
pygui.moveTo(1282, 380)
pygui.click(button = 'right')
pygui.moveTo(1282, 528)
pygui.moveTo(1382, 528, duration = 0.5)
pygui.moveTo(1582, 528, )
pygui.click(button = 'left')
def selectPrevWeek():
pygui.moveTo(275,745)
pygui.click(button = 'left')
pygui.scroll(-110)
copyTable()
#pasteToFile()
#selectPrevWeek()
reticulate::repl_python()
quit
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)#tidy
library(spotifyr)#spotify web api wrapper class
library(stringr)#string processing
library(ggplot2)#ggplot for testing
library(lubridate) #dates
library(readr) #text file reading
library(knitr) #live knit files
library(reticulate) #python cells and interaction with R requires miniConda
#install.packages("remotes") #
#remotes::install_github("mvkorpel/pickURL")
reticulate::repl_python()
x= 540
y= 755 # or 760
copyTable()
pygui.scroll(-500)
#
# iters=5
# for i in range(iters):
#   copyTable()
#   pasteToFile('AutoData.txt')
#   selectPrevWeek(x,y)
#   y = update_y(y)
#
def pasteToFile(filename = "Autodata.txt"):
f=open(filename, "a", encoding="utf-8")
win32clipboard.OpenClipboard()
data = win32clipboard.GetClipboardData()
cdata= "\n\n\n"+ str(data)
if(cdata != None):
print("got data!\n")
f.write(cdata)
win32clipboard.CloseClipboard()
f.close()
def copyTable():
pygui.moveTo(161, 787)
pygui.click(button = 'right')
pygui.moveTo(161, 767)
pygui.click(button = 'left')
pygui.moveTo(1282, 380,duration = 0.5)
pygui.click(button = 'right')
pygui.moveTo(1282, 528,duration = 0.5)
pygui.moveTo(1382, 528,duration = 0.5)
pygui.moveTo(1582, 528,duration = 0.5)
pygui.click(button = 'left')
def update_x(x):
x_min = 230
x_max = 540
if(x > x_min and x < x_max):
x=- 300
else:
x= x_max
return x
def update_y(y):
y_min = 590
y_max = 760
if(y > y_min and y < y_max):
y= y - 35
if(y < y_min):
y = y_max
return y
def selectPrevWeek(x,y):
pygui.moveTo(279,331, duration = 0.5)
pygui.scroll(-500)
pygui.click(button = 'left', duration =0.6)
pygui.moveTo(540,y, duration = 0.5)
pygui.click(button = 'left')
pygui.hotkey('ctrl','r')
import pyautogui as pygui
import win32clipboard
import sys
x= 540
y= 755 # or 760
copyTable()
pygui.scroll(-500)
#
# iters=5
# for i in range(iters):
#   copyTable()
#   pasteToFile('AutoData.txt')
#   selectPrevWeek(x,y)
#   y = update_y(y)
#
x= 540
y= 755 # or 760
copyTable()
selectPrevWeek(x,y)
#
# iters=5
# for i in range(iters):
#   copyTable()
#   pasteToFile('AutoData.txt')
#   selectPrevWeek(x,y)
#   y = update_y(y)
#
x= 540
y= 755 # or 760
copyTable()
selectPrevWeek(x,y)
#
# iters=5
# for i in range(iters):
#   copyTable()
#   pasteToFile('AutoData.txt')
#   selectPrevWeek(x,y)
#   y = update_y(y)
#
x= 540
y= 755 # or 760
copyTable()
pygui.scroll(-500)
pygui.click(button = 'left', duration =0.6)
pygui.moveTo(540,y, duration = 0.5)
#
# iters=5
# for i in range(iters):
#   copyTable()
#   pasteToFile('AutoData.txt')
#   selectPrevWeek(x,y)
#   y = update_y(y)
#
x= 540
y= 755 # or 760
copyTable()
pygui.scroll(-500)
pygui.moveTo(540,y, duration = 0.5)
pygui.click(button = 'left', duration =0.6)
#
# iters=5
# for i in range(iters):
#   copyTable()
#   pasteToFile('AutoData.txt')
#   selectPrevWeek(x,y)
#   y = update_y(y)
#
x= 540
y= 755 # or 760
copyTable()
pygui.moveTo(279,331, duration = 0.5)
pygui.scroll(-500)
#
# iters=5
# for i in range(iters):
#   copyTable()
#   pasteToFile('AutoData.txt')
#   selectPrevWeek(x,y)
#   y = update_y(y)
#
print('Press Ctrl-C to quit.')
try:
while True:
x, y = pygui.position()
positionStr = 'X: ' + str(x).rjust(4) + ' Y: ' + str(y).rjust(4)
print(positionStr, end='')
print('\b' * len(positionStr), end='', flush=True)
except KeyboardInterrupt:
print('\n')
print('Press Ctrl-C to quit.')
reticulate::repl_python()
import pyautogui as pygui
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)#tidy
library(spotifyr)#spotify web api wrapper class
library(lubridate) #dates
library(readr) #text file reading
library(knitr) #live knit cells
library(reticulate) #python cells and interaction with R requires miniConda
F_Scrape_day = "2022-03-31" #Final Scrape day
I_Scrape_day = "2021-10-21" #Intial Scrape day
#Generate our sequence of dates using lubridate
dateSeq = seq.Date(from = as.Date(I_Scrape_day), to = as.Date(F_Scrape_day), by = 'weeks')
#Convert to python list
datesSeqAsPyL = r_to_py(dateSeq)
reticulate::repl_python()
import pyautogui as pygui
import datetime as dt
import win32clipboard
import random
def pasteToFile(filename = "Autodata.txt", curDate = "X"):
f=open(filename, "a", encoding="utf-8")
win32clipboard.OpenClipboard()
data = win32clipboard.GetClipboardData()
cdata=  "\n\nSDateHere:" + str(curDate) + "\n\n"+ str(data)
if(cdata != None):
print("got data!\n")
f.write(cdata)
win32clipboard.CloseClipboard()
f.close()
def copyTable():
pygui.moveTo(161, 787)
pygui.click(button = 'right')
pygui.moveTo(161, 767)
pygui.PAUSE = random.uniform(0,1)
pygui.click(button = 'left')
pygui.moveTo(1282, 380, duration = 0.5)
pygui.click(button = 'right')
pygui.PAUSE = random.uniform(0,0.9)
pygui.moveTo(1282, 528, duration = 0.5)
pygui.moveTo(1382, 528, duration = 0.5)
pygui.moveTo(1582, 528, duration = 0.5)
pygui.click(button = 'left')
pygui.PAUSE = random.uniform(0,0.4)
def goToPrevWeek(date):
pygui.press('F6')
pygui.press('delete')
randf = random.uniform(0,0.7)
pygui.typewrite("https://charts.spotify.com/charts/view/citypulsetrack-denver-weekly/" + date, interval = 0.1)
pygui.PAUSE = random.uniform(0,1)
pygui.press('enter')
def beginScrape():
dseq = [dateobj.strftime('%Y-%m-%d') for dateobj in r.datesSeqAsPyL]
dseq = list(reversed(dseq))
for i in dseq:
pygui.hotkey('ctrl', 'r')
copyTable()
pasteToFile("raw_data/AutoData.txt", i)
goToPrevWeek(i)
pygui.PAUSE = random.uniform(0,3)
#beginScrape()
quit
id ='71e950603dd64e1291d04fabafee04d9'
secret = '5331da62c4644ee887ff07216c35b183'
Sys.setenv(SPOTIFY_CLIENT_ID = id)
Sys.setenv(SPOTIFY_CLIENT_SECRET = secret)
access_token <- get_spotify_access_token() #
p_id = "zain_elsell"  # personal id
# ----------------------------------------------------------------------------------------------
# params raw html table class you want to scrape .txt file name/ do you want just the song song keys? / do yo you want the full links to the tracks?
scrape_table = function(file_name, keys=1, links=0)
{
url_pattern = "https://open.spotify.com/track/"  # track link pattern
exKey = "26wuBc04catG1QQyYupr35"
songlinks = c()  # blank vector to store just song links
sLinksIndex = str_locate_all(read_file(file_name), url_pattern) %>% data.frame()
for(i in sLinksIndex$start){
songlinks = c(songlinks, str_sub(read_file(file_name), start = i, end= (i+nchar(url_pattern)+nchar(exKey))-1))
}
if(keys){
songKeys = str_replace_all(songlinks, url_pattern , "")
songKeys = rle(songKeys)$values
}
else if(links){return(songlinks)}
else return(songKeys)
}
# ---------------------------------------------------------------------------------------------
key_to_df <-function(x){
df <-data.frame()
names <- c()
artist_names <- c()
for (i in x){
df <-rbind(df, get_track_audio_features(i))} # binds all of the audio features together
for (i in df$id){ # adds the name of the song and the artist to the df
name2 <- c(get_tracks(i)[["name"]])
names = c(names, name2)
temp <- get_tracks(i)[1]
tempdf <- data.frame(temp[[1]])
tempname <- tempdf[["name"]][1]
artist_names = c(artist_names, tempname)}
df <- df %>% mutate(song_name=(names), artist_name=artist_names) %>%
relocate(artist_name) %>%
relocate(song_name)# this just rearranging columns
df <- df %>%
select(-c(mode, type, uri,track_href, analysis_url)) #removing useless columns
df <- cbind(df, week=rep(rev(dateSeq), each=100))
return(df)
}
# ----------------------------------------------------------------------------------------------
# For testing use local pulse march 28 so we have control for values to expect
# raw_html_file_name = "raw_data/Local_Pulse_March_28.txt"
# songKeys = scrape_table(raw_html_file_name)
# trackDf = key_to_df(songKeys)
p_id = "zain_elsell"  # personal id
# ----------------------------------------------------------------------------------------------
# params raw html table class you want to scrape .txt file name/ do you want just the song song keys? / do yo you want the full links to the tracks?
scrape_table = function(file_name, keys=1, links=0)
{
url_pattern = "https://open.spotify.com/track/"  # track link pattern
exKey = "26wuBc04catG1QQyYupr35"
songlinks = c()  # blank vector to store just song links
sLinksIndex = str_locate_all(read_file(file_name), url_pattern) %>% data.frame()
for(i in sLinksIndex$start){
songlinks = c(songlinks, str_sub(read_file(file_name), start = i, end= (i+nchar(url_pattern)+nchar(exKey))-1))
}
if(keys){
songKeys = str_replace_all(songlinks, url_pattern , "")
songKeys = rle(songKeys)$values
}
else if(links){return(songlinks)}
else return(songKeys)
}
# ---------------------------------------------------------------------------------------------
key_to_df <-function(x){
df <-data.frame()
names <- c()
artist_names <- c()
for (i in x){
df <-rbind(df, get_track_audio_features(i))} # binds all of the audio features together
for (i in df$id){ # adds the name of the song and the artist to the df
name2 <- c(get_tracks(i)[["name"]])
names = c(names, name2)
temp <- get_tracks(i)[1]
tempdf <- data.frame(temp[[1]])
tempname <- tempdf[["name"]][1]
artist_names = c(artist_names, tempname)}
df <- df %>% mutate(song_name=(names), artist_name=artist_names) %>%
relocate(artist_name) %>%
relocate(song_name)# this just rearranging columns
df <- df %>%
select(-c(mode, type, uri,track_href, analysis_url)) #removing useless columns
df <- cbind(df, week=rep(rev(dateSeq), each=100))
return(df)
}
# ----------------------------------------------------------------------------------------------
# For testing use local pulse march 28 so we have control for values to expect
# raw_html_file_name = "raw_data/Local_Pulse_March_28.txt"
# songKeys = scrape_table(raw_html_file_name)
# trackDf = key_to_df(songKeys)
raw_html_file_name = "raw_data/AutoData.txt"
songKeys = scrape_table(raw_html_file_name)
songKeys
trackDf = key_to_df(songKeys)
head(trackDf)
path_to_csv = "C:\\Users\\zaine\\OneDrive\\Desktop\\School\\STAT\\spotify_data_proj\\clean_data\\trackData.csv"
res = write.csv(trackDf,path_to_csv)
install.packages("tidyverse")
Y
library(boot)
detach("package:boot", unload = TRUE)
library(class)
detach("package:class", unload = TRUE)
library(here)
library(jsonlite)
detach("package:here", unload = TRUE)
library(here)
library(tools)
install.packages(c("cluster", "MASS", "Matrix", "mgcv", "nlme", "survival"))
install.packages(c("cluster", "MASS", "Matrix", "mgcv", "nlme", "survival"))
install.packages(c("cluster", "MASS", "Matrix", "mgcv", "nlme", "survival"))
install.packages(c("spotifyr","lubridate","reticualte","knitr","readr"))
install.packages("tidybins")
install.packages("tidyverse")
install.packages("rmarkdown")
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
set.seed(2022) #Controlled random
dpath = "clean_data/trackData.csv"#CSV path
data = read.csv(dpath)#Import data from CSV in the same directory
#////////////////////////////////////////////////////////////////////////////////////////////
#Are we using pure ranking or ranking avg rank week?
#1 if avg rank 0 if just rank
rank_xor = 0
#WARNING: If predicing average ranking then every refrence to ranking should be changed to rankingX!
#If you don't do that none of the code will execute this if statment simply toggles the processing of the data frame.
if(rank_xor==1){
avg = data %>%
group_by(song_name)  %>%
summarise(s_freq = sum(ranking), weeks_trending = n()) %>%
mutate(ranking = s_freq / weeks_trending)
data = merge(avg, data, by="song_name")
data = select(data, -c(week, ranking, id,X,s_freq))
data=distinct(data)
}
head(data)
set.seed(2022) #Controlled random
dpath = "clean_data/trackData.csv"#CSV path
data = read.csv(dpath)#Import data from CSV in the same directory
#////////////////////////////////////////////////////////////////////////////////////////////
#Are we using pure ranking or ranking avg rank week?
#1 if avg rank 0 if just rank
rank_xor = 0
#WARNING: If predicing average ranking then every refrence to ranking should be changed to rankingX!
#If you don't do that none of the code will execute this if statment simply toggles the processing of the data frame.
if(rank_xor==1){
avg = data %>%
group_by(song_name)  %>%
summarise(s_freq = sum(ranking), weeks_trending = n()) %>%
mutate(ranking = s_freq / weeks_trending)
data = merge(avg, data, by="song_name")
data = select(data, -c(week, ranking, id,X,s_freq))
data=distinct(data)
}
head(data)
colnames(data)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)#tidy
library(spotifyr)#spotify web api wrapper class
library(lubridate) #dates
library(readr) #text file reading
library(knitr) #live knit cells
library(reticulate) #python cells and interaction with R requires miniConda
raw_html_file_name = "raw_data/AutoData.txt"
songKeys = scrape_table(raw_html_file_name)
raw_html_file_name = "raw_data/AutoData.txt"
songKeys = scrape_table(raw_html_file_name)
raw_html_file_name = "raw_data/AutoData.txt"
songKeys = scrape_table(raw_html_file_name)
raw_html_file_name = "raw_data/AutoData.txt"
songKeys = scrape_table(raw_html_file_name)
